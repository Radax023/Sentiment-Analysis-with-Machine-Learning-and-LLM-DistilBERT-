{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rIaMQ17h134"
      },
      "source": [
        "# Sentiment Analysis using Machine Learning and LLM (DistilBERT)\n",
        "**Author:** Reza Adousi  \n",
        "**Date:** 2025  \n",
        "**Dataset:** Amazon Product Reviews  \n",
        "**Goal:** Compare traditional ML models (Logistic Regression, SVM, Naive Bayes) with a modern LLM (DistilBERT) and combine them using Stacking Ensemble for sentiment prediction."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Install requirements ===\n",
        "!pip install -q gdown pandas numpy scikit-learn transformers torch"
      ],
      "metadata": {
        "id": "daLpfW5gbFQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Data Loading and Cleaning"
      ],
      "metadata": {
        "id": "u6dTyxOTbQsM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBSypYmwgeb3",
        "outputId": "491ad9d8-1738-468f-b62d-edf0fe682385"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1zBrBGoteMOCnU8MW8N291G03kFeU_CJT\n",
            "From (redirected): https://drive.google.com/uc?id=1zBrBGoteMOCnU8MW8N291G03kFeU_CJT&confirm=t&uuid=a01537ba-9674-41c3-9b36-0b89f8d4d5e2\n",
            "To: /content/Reviews.csv\n",
            "100% 301M/301M [00:02<00:00, 106MB/s] \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 568454 entries, 0 to 568453\n",
            "Data columns (total 10 columns):\n",
            " #   Column                  Non-Null Count   Dtype \n",
            "---  ------                  --------------   ----- \n",
            " 0   Id                      568454 non-null  int64 \n",
            " 1   ProductId               568454 non-null  object\n",
            " 2   UserId                  568454 non-null  object\n",
            " 3   ProfileName             568428 non-null  object\n",
            " 4   HelpfulnessNumerator    568454 non-null  int64 \n",
            " 5   HelpfulnessDenominator  568454 non-null  int64 \n",
            " 6   Score                   568454 non-null  int64 \n",
            " 7   Time                    568454 non-null  int64 \n",
            " 8   Summary                 568427 non-null  object\n",
            " 9   Text                    568454 non-null  object\n",
            "dtypes: int64(5), object(5)\n",
            "memory usage: 43.4+ MB\n",
            "None\n",
            "Id                         0\n",
            "ProductId                  0\n",
            "UserId                     0\n",
            "ProfileName               26\n",
            "HelpfulnessNumerator       0\n",
            "HelpfulnessDenominator     0\n",
            "Score                      0\n",
            "Time                       0\n",
            "Summary                   27\n",
            "Text                       0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "!gdown 1zBrBGoteMOCnU8MW8N291G03kFeU_CJT # download dataset from google drive\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.read_csv('./Reviews.csv')  # load reviews\n",
        "print(df.info())\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8xawuFsh9pc",
        "outputId": "cf8c2d95-2436-41f4-db8e-ba77de92b95f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 525763 entries, 0 to 568453\n",
            "Data columns (total 10 columns):\n",
            " #   Column                  Non-Null Count   Dtype \n",
            "---  ------                  --------------   ----- \n",
            " 0   Id                      525763 non-null  int64 \n",
            " 1   ProductId               525763 non-null  object\n",
            " 2   UserId                  525763 non-null  object\n",
            " 3   ProfileName             525763 non-null  object\n",
            " 4   HelpfulnessNumerator    525763 non-null  int64 \n",
            " 5   HelpfulnessDenominator  525763 non-null  int64 \n",
            " 6   Score                   525763 non-null  int64 \n",
            " 7   Time                    525763 non-null  int64 \n",
            " 8   Summary                 525763 non-null  object\n",
            " 9   Text                    525763 non-null  object\n",
            "dtypes: int64(5), object(5)\n",
            "memory usage: 44.1+ MB\n",
            "None\n",
            "Id                        0\n",
            "ProductId                 0\n",
            "UserId                    0\n",
            "ProfileName               0\n",
            "HelpfulnessNumerator      0\n",
            "HelpfulnessDenominator    0\n",
            "Score                     0\n",
            "Time                      0\n",
            "Summary                   0\n",
            "Text                      0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "df.drop_duplicates(inplace=True)\n",
        "df.dropna(inplace=True)\n",
        "df = df[df['Score'] != 3]\n",
        "\n",
        "print(df.info())\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "T0XHgFr7iBtB"
      },
      "outputs": [],
      "source": [
        "df['label'] = df['Score'].apply(lambda x: 1 if x >= 4 else 0)\n",
        "texts = df['Text'].tolist()\n",
        "labels = df['label'].tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Train-Test Split and Text Vectorization"
      ],
      "metadata": {
        "id": "cn_x9bvub8a2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iDSzfSvIize",
        "outputId": "f9ccf165-c424-4f4c-9f4d-0f47ffedc052"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "420610 105153\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "print(len(X_train), len(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "id": "XO19Jw6VQI3H"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=500)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "\n",
        "#print(vectorizer.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Classical Machine Learning Models\n",
        "\n",
        "We train three baseline models:\n",
        "- Logistic Regression  \n",
        "- Support Vector Machine (SVM)  \n",
        "- Naive Bayes  \n",
        "We will evaluate each model using accuracy."
      ],
      "metadata": {
        "id": "GvvUx7TmcRxw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KkmccgPEotj_"
      },
      "outputs": [],
      "source": [
        "# Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression()\n",
        "\n",
        "lr.fit(X_train_tfidf, y_train)\n",
        "lr_probs_train = lr.predict_proba(X_train_tfidf)[:,1]\n",
        "lr_probs_test = lr.predict_proba(X_test_tfidf)[:,1]\n",
        "\n",
        "\n",
        "LR_pred = (lr_probs_test >= 0.5).astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3P9K-q3YpMDc"
      },
      "outputs": [],
      "source": [
        "# SVM\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "svc = LinearSVC()\n",
        "\n",
        "svm_calibrated = CalibratedClassifierCV(svc)\n",
        "svm_calibrated.fit(X_train_tfidf, y_train)\n",
        "svm_probs_train = svm_calibrated.predict_proba(X_train_tfidf)[:,1]\n",
        "svm_probs_test = svm_calibrated.predict_proba(X_test_tfidf)[:,1]\n",
        "\n",
        "\n",
        "SVC_pred = (svm_probs_test >= 0.5).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OIi2KcNTqRsZ"
      },
      "outputs": [],
      "source": [
        "# Naive Bayes (MultinomialNB)\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "nb = MultinomialNB()\n",
        "\n",
        "nb.fit(X_train_tfidf, y_train)\n",
        "nb_probs_train = nb.predict_proba(X_train_tfidf)[:,1]\n",
        "nb_probs_test = nb.predict_proba(X_test_tfidf)[:,1]\n",
        "\n",
        "\n",
        "NB_pred = (nb_probs_test >= 0.5).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "sLB9WghXqr2_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f279970-9aac-4edb-b14f-326d0d7da59b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression: 0.8974\n",
            "SVM: 0.8977\n",
            "Naive Bayes: 0.8457\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "models = {\n",
        "    \"Logistic Regression\": LR_pred,\n",
        "    \"SVM\": SVC_pred,\n",
        "    \"Naive Bayes\": NB_pred,\n",
        "}\n",
        "\n",
        "for name, pred in models.items():\n",
        "    print(f\"{name}: {accuracy_score(y_test, pred):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the results, we selected SVM and Logistic Regression as the traditional models to be combined with the LLM in the next stage."
      ],
      "metadata": {
        "id": "frDXFbP4cxOc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeE04Ls5vHqu"
      },
      "source": [
        "4. LLM (DistilBERT) Sentiment Analysis\n",
        "\n",
        "Now we use a pre-trained transformer model, **DistilBERT**, fine-tuned for sentiment classification.\n",
        "We test it on a filtered subset (short reviews with ≤ 512 tokens)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "id": "a9pZshUKSM8U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301,
          "referenced_widgets": [
            "42d300febb2f4159beffe2555bab2d31",
            "1c96e6d2ce874a6e9e6c9c6137d57485",
            "e15bb08aa1d74409abf4c2761d418d5c",
            "e6828991f3f14a7d9043686958dcc7d6",
            "4affeaf5fad042f8a386aaffa883b9a0",
            "c1a1b15e4980423985129279e5dd3156",
            "618441d613bd43e39387e25a23c5791a",
            "5684d5d300ce4e95a128a157e4d583aa",
            "daa598caef3846b989f12ff9792ca998",
            "0b837eaea9034b908fb9dbd6e451d3f6",
            "89cc7a06304a4e49975df4af1d8d781e",
            "85f424350a324404991a34a20d829fa2",
            "f4dca57c6bc74ddbbca0612070ed2746",
            "f0585f83f74444b8afcc0661cd93412e",
            "b49ab41c118e4729bdeeade522748dd9",
            "d9caa387212045e6a18c68236401b5ee",
            "6792395aa89c447092ee25fb7831619e",
            "6290be47b2794fa781e54be66394c9c3",
            "b07e4f63afca48dea93577bba8472461",
            "404b82484e3a46ddad898e7d5ab2ce4a",
            "c07f3f855f624031b1a782726a6d695c",
            "d6751e9628284cb1b79be34ab16da527",
            "6faef555707849d2a242117356bb0c46",
            "e3610da0652d41f49de1eccf9eab8eb7",
            "6f328b8b22994434bac3282fb7fd9e18",
            "cc22b4ea7b504f9397ba560c9334dd13",
            "ce41406c182c407b82e2f6691840c3da",
            "38c1a801b57745efab2206b33951a2dd",
            "880665cfdd0943db94ad9a39a3ff8dda",
            "dd51d66739424718ba1e3b53c5ec577a",
            "626429c55760496f953a7044ce0704be",
            "7b9e8e09a25e48c69011052a45f83fd3",
            "9d54879fa2ce4b429defacabcfbb46b1",
            "7455971b899547cf949429f792567ccc",
            "56eb5b132f694c45aa94763f6267092c",
            "c1b1c02922b84a7c822705085153beef",
            "fdb63019a0244a55b2b5e8d9cbd8ba54",
            "f30f8e28597b4bc483f0b79232a936fe",
            "caa4f185ca104386ad72584cc61091da",
            "dfdaf6b295a049fb902446206096935a",
            "f2334fc940a549e693c57727f3bb8cbd",
            "6ac8d292b8d34c2182adc6a5b32156f7",
            "3460a56df9574699ab5097055d630c98",
            "0f60072b6db641e8a99f9e6a86c4db2f"
          ]
        },
        "outputId": "21c83a70-d946-4b22-8a62-4b9ee7eabcd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
            "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
            "You are not authenticated with the Hugging Face Hub in this notebook.\n",
            "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "42d300febb2f4159beffe2555bab2d31"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "85f424350a324404991a34a20d829fa2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6faef555707849d2a242117356bb0c46"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7455971b899547cf949429f792567ccc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (679 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Original: 420610, Filtered: 9885\n",
            "Test Original: 105153, Filtered: 4951\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline, AutoTokenizer\n",
        "import numpy as np\n",
        "\n",
        "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "\n",
        "llm = pipeline(\"sentiment-analysis\", model=model_name)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "\n",
        "# === Test subset ===\n",
        "subset_idx_train = np.random.choice(len(X_train), size=10000, replace=False)\n",
        "lengths_train = [len(tokenizer.encode(X_train[i])) for i in subset_idx_train]\n",
        "filtered_idx_train = [idx for idx, l in zip(subset_idx_train, lengths_train) if l <= 512]\n",
        "\n",
        "X_train_filtered = [X_train[i] for i in filtered_idx_train]\n",
        "y_train_filtered = [y_train[i] for i in filtered_idx_train]\n",
        "\n",
        "\n",
        "print(f\"Train Original: {len(X_train)}, Filtered: {len(X_train_filtered)}\")\n",
        "\n",
        "# === Train subset ===\n",
        "subset_idx_test = np.random.choice(len(X_test), size=5000, replace=False)\n",
        "lengths_test = [len(tokenizer.encode(X_test[i])) for i in subset_idx_test]\n",
        "filtered_idx_test = [idx for idx, l in zip(subset_idx_test, lengths_test) if l <= 512]\n",
        "\n",
        "X_test_filtered = [X_test[i] for i in filtered_idx_test]\n",
        "y_test_filtered = [y_test[i] for i in filtered_idx_test]\n",
        "\n",
        "print(f\"Test Original: {len(X_test)}, Filtered: {len(X_test_filtered)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "PrsdnkFv75Vd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eda1a0c1-753c-4855-9288-0c6af0b1e1bc"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        }
      ],
      "source": [
        "def llm_to_prob_batch(text_list, batch_size=512):\n",
        "    probs = []\n",
        "    for i in range(0, len(text_list), batch_size):\n",
        "        batch = text_list[i:i+batch_size]\n",
        "        preds = llm(batch)\n",
        "        for pred in preds:\n",
        "            probs.append(pred['score'] if pred['label'] in ['LABEL_2','POSITIVE'] else 1-pred['score'])\n",
        "    return np.array(probs)\n",
        "\n",
        "llm_probs_test = llm_to_prob_batch(X_test_filtered)\n",
        "llm_probs_train = llm_to_prob_batch(X_train_filtered)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27kEhmRrVW3e",
        "outputId": "2b260241-935f-427d-9cb9-97320858d4a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM Accuracy: 0.8497273278125631\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.89      0.64       749\n",
            "           1       0.98      0.84      0.90      4202\n",
            "\n",
            "    accuracy                           0.85      4951\n",
            "   macro avg       0.74      0.87      0.77      4951\n",
            "weighted avg       0.91      0.85      0.87      4951\n",
            "\n"
          ]
        }
      ],
      "source": [
        "llm_pred = (llm_probs_test >= 0.5).astype(int)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "accuracy = accuracy_score(y_test_filtered, llm_pred)\n",
        "print(\"LLM Accuracy:\", accuracy)\n",
        "\n",
        "print(classification_report(y_test_filtered, llm_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Stacking Ensemble\n",
        "\n",
        "We combine Logistic Regression, SVM, and LLM predictions using a meta Logistic Regression model (stacking)."
      ],
      "metadata": {
        "id": "dg8X5H2vfIi-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "MnBOYXhw5V10"
      },
      "outputs": [],
      "source": [
        "lr_train_filtered = lr_probs_train[filtered_idx_train]\n",
        "svm_train_filtered = svm_probs_train[filtered_idx_train]\n",
        "\n",
        "lr_test_filtered = lr_probs_test[filtered_idx_test]\n",
        "svm_test_filtered = svm_probs_test[filtered_idx_test]\n",
        "\n",
        "# Stacking\n",
        "X_stack_train = np.column_stack((lr_train_filtered, svm_train_filtered, llm_probs_train))\n",
        "X_stack_test = np.column_stack((lr_test_filtered, svm_test_filtered, llm_probs_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "sAM395n9dT24"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "stack_model = LogisticRegression()\n",
        "stack_model.fit(X_stack_train, y_train_filtered)\n",
        "\n",
        "stack_probs = stack_model.predict_proba(X_stack_test)[:,1]\n",
        "stack_pred = (stack_probs >= 0.5).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "iqF5iWTH5msb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c927f7db-2b6b-4f04-cdce-31844d4da981"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Accuracy: 0.916380529186023\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.66      0.71       749\n",
            "           1       0.94      0.96      0.95      4202\n",
            "\n",
            "    accuracy                           0.92      4951\n",
            "   macro avg       0.85      0.81      0.83      4951\n",
            "weighted avg       0.91      0.92      0.91      4951\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "print(\"Stacking Accuracy:\", accuracy_score(y_test_filtered, stack_pred))\n",
        "print(classification_report(y_test_filtered, stack_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results & Discussion\n",
        "\n",
        "Below are the accuracy results for each model:\n",
        "\n",
        "| Model | Accuracy |\n",
        "|:------|:---------:|\n",
        "| Logistic Regression | **0.8974** |\n",
        "| SVM | **0.8977** |\n",
        "| Naive Bayes | 0.8457 |\n",
        "| LLM (DistilBERT) | 0.8478 |\n",
        "| **Stacking Ensemble** | **0.9180** |\n",
        "\n",
        "\n",
        "- Both **SVM** and **Logistic Regression** achieved very similar accuracy (~0.89).\n",
        "- The **LLM (DistilBERT)** performed comparably to the traditional models, showing strong contextual understanding but limited by smaller input samples (≤512 tokens).\n",
        "- The **Stacking Ensemble**, which combines the predictions of SVM, Logistic Regression, and the LLM, achieved the **highest accuracy (0.918)**.\n",
        "\n",
        "### Conclusion\n",
        "\n",
        "The results confirm that while classical models remain strong for text classification, combining them with modern LLMs through **stacking** yields the best overall performance.\n"
      ],
      "metadata": {
        "id": "X1SmNZtQfRw0"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}